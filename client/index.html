<!DOCTYPE html>
<html lang="cs">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ultra-Fast Voice AI - EniQ Assistant</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, sans-serif;
            background: linear-gradient(135deg, #1a1a2e 0%, #16213e 50%, #0f3460 100%);
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 20px;
        }

        .container {
            background: rgba(255, 255, 255, 0.05);
            backdrop-filter: blur(10px);
            border-radius: 24px;
            padding: 40px;
            width: 100%;
            max-width: 600px;
            box-shadow: 0 25px 50px -12px rgba(0, 0, 0, 0.5);
            border: 1px solid rgba(255, 255, 255, 0.1);
        }

        h1 {
            color: #fff;
            text-align: center;
            margin-bottom: 10px;
            font-size: 28px;
            font-weight: 600;
        }

        .subtitle {
            color: rgba(255, 255, 255, 0.6);
            text-align: center;
            margin-bottom: 30px;
            font-size: 14px;
        }

        .status-bar {
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 10px;
            margin-bottom: 30px;
            padding: 12px 20px;
            background: rgba(0, 0, 0, 0.3);
            border-radius: 12px;
        }

        .status-indicator {
            width: 12px;
            height: 12px;
            border-radius: 50%;
            background: #666;
            transition: all 0.3s ease;
        }

        .status-indicator.connected {
            background: #4ade80;
            box-shadow: 0 0 10px #4ade80;
        }

        .status-indicator.listening {
            background: #60a5fa;
            box-shadow: 0 0 10px #60a5fa;
            animation: pulse 1.5s infinite;
        }

        .status-indicator.speaking {
            background: #f472b6;
            box-shadow: 0 0 10px #f472b6;
            animation: pulse 0.8s infinite;
        }

        @keyframes pulse {
            0%, 100% { opacity: 1; transform: scale(1); }
            50% { opacity: 0.7; transform: scale(1.1); }
        }

        .status-text {
            color: rgba(255, 255, 255, 0.8);
            font-size: 14px;
        }

        .button-container {
            display: flex;
            justify-content: center;
            margin-bottom: 30px;
        }

        .start-button {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border: none;
            padding: 18px 50px;
            font-size: 18px;
            font-weight: 600;
            border-radius: 50px;
            cursor: pointer;
            transition: all 0.3s ease;
            box-shadow: 0 10px 30px rgba(102, 126, 234, 0.4);
        }

        .start-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 15px 40px rgba(102, 126, 234, 0.5);
        }

        .start-button:active {
            transform: translateY(0);
        }

        .start-button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
            transform: none;
        }

        .start-button.active {
            background: linear-gradient(135deg, #ef4444 0%, #dc2626 100%);
            box-shadow: 0 10px 30px rgba(239, 68, 68, 0.4);
        }

        .transcript-container {
            background: rgba(0, 0, 0, 0.3);
            border-radius: 16px;
            padding: 20px;
            margin-bottom: 20px;
            max-height: 300px;
            overflow-y: auto;
        }

        .transcript-label {
            color: rgba(255, 255, 255, 0.5);
            font-size: 12px;
            text-transform: uppercase;
            letter-spacing: 1px;
            margin-bottom: 10px;
        }

        .transcript-content {
            color: rgba(255, 255, 255, 0.9);
            font-size: 16px;
            line-height: 1.6;
            min-height: 60px;
        }

        .transcript-content .user-text {
            color: #60a5fa;
        }

        .transcript-content .assistant-text {
            color: #4ade80;
        }

        .transcript-content .interim {
            opacity: 0.6;
            font-style: italic;
        }

        .message {
            margin-bottom: 12px;
            padding: 8px 12px;
            border-radius: 8px;
        }

        .message.user {
            background: rgba(96, 165, 250, 0.1);
            border-left: 3px solid #60a5fa;
        }

        .message.assistant {
            background: rgba(74, 222, 128, 0.1);
            border-left: 3px solid #4ade80;
        }

        .message-label {
            font-size: 11px;
            color: rgba(255, 255, 255, 0.4);
            margin-bottom: 4px;
        }

        .visualizer-container {
            display: flex;
            justify-content: center;
            align-items: center;
            gap: 4px;
            height: 60px;
            margin-bottom: 20px;
        }

        .visualizer-bar {
            width: 4px;
            background: linear-gradient(to top, #667eea, #764ba2);
            border-radius: 2px;
            transition: height 0.1s ease;
        }

        .debug-info {
            background: rgba(0, 0, 0, 0.3);
            border-radius: 12px;
            padding: 15px;
            font-family: monospace;
            font-size: 12px;
            color: rgba(255, 255, 255, 0.5);
            max-height: 150px;
            overflow-y: auto;
        }

        .debug-info .log-entry {
            margin-bottom: 4px;
        }

        .debug-info .log-entry.error {
            color: #ef4444;
        }

        .debug-info .log-entry.success {
            color: #4ade80;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>‚ö° Ultra-Fast Voice AI</h1>
        <p class="subtitle">Google Speech V2 ‚Ä¢ Llama 3.3 70B ‚Ä¢ ElevenLabs Flash v2.5</p>

        <div class="status-bar">
            <div class="status-indicator" id="statusIndicator"></div>
            <span class="status-text" id="statusText">Odpojeno</span>
        </div>

        <div class="visualizer-container" id="visualizer">
            <!-- Audio visualizer bars will be created by JS -->
        </div>

        <div class="button-container">
            <button class="start-button" id="startButton">Spustit</button>
        </div>

        <div class="transcript-container">
            <div class="transcript-label">Konverzace</div>
            <div class="transcript-content" id="transcriptContent">
                <p style="color: rgba(255,255,255,0.4); font-style: italic;">Kliknƒõte na "Spustit" pro zah√°jen√≠ konverzace...</p>
            </div>
        </div>

        <div class="debug-info" id="debugInfo">
            <div class="log-entry">P≈ôipraveno k pou≈æit√≠</div>
        </div>
    </div>

    <script>
        // Configuration - Ultra-Fast Voice AI
        // Use wss:// for HTTPS (cloudflare), ws:// for HTTP (local)
        const WS_PROTOCOL = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
        const WS_URL = `${WS_PROTOCOL}//${window.location.host}/ws`;
        
        // Audio config for Google Cloud Speech V2 (Chirp 2)
        const SAMPLE_RATE = 16000;  // 16kHz LINEAR16 PCM required by Google
        const CHANNELS = 1;          // Mono audio

        // State
        let websocket = null;
        let mediaStream = null;
        let audioContext = null;
        let audioWorklet = null;
        let isActive = false;
        let audioQueue = [];
        let isPlayingAudio = false;
        let assistantIsSpeaking = false;  // Track if assistant is speaking to pause mic
        let currentUserText = '';
        let currentAssistantText = '';

        // DOM Elements
        const startButton = document.getElementById('startButton');
        const statusIndicator = document.getElementById('statusIndicator');
        const statusText = document.getElementById('statusText');
        const transcriptContent = document.getElementById('transcriptContent');
        const debugInfo = document.getElementById('debugInfo');
        const visualizer = document.getElementById('visualizer');

        // Initialize visualizer bars
        function initVisualizer() {
            visualizer.innerHTML = '';
            for (let i = 0; i < 32; i++) {
                const bar = document.createElement('div');
                bar.className = 'visualizer-bar';
                bar.style.height = '4px';
                visualizer.appendChild(bar);
            }
        }

        // Update visualizer with audio levels
        function updateVisualizer(levels) {
            const bars = visualizer.querySelectorAll('.visualizer-bar');
            bars.forEach((bar, i) => {
                const level = levels[i] || 0;
                bar.style.height = `${4 + level * 56}px`;
            });
        }

        // Reset visualizer
        function resetVisualizer() {
            const bars = visualizer.querySelectorAll('.visualizer-bar');
            bars.forEach(bar => {
                bar.style.height = '4px';
            });
        }

        // Logging
        function log(message, type = 'info') {
            const entry = document.createElement('div');
            entry.className = `log-entry ${type}`;
            entry.textContent = `[${new Date().toLocaleTimeString()}] ${message}`;
            debugInfo.insertBefore(entry, debugInfo.firstChild);
            
            // Keep only last 50 entries
            while (debugInfo.children.length > 50) {
                debugInfo.removeChild(debugInfo.lastChild);
            }
            
            console.log(`[${type.toUpperCase()}]`, message);
        }

        // Update status
        function setStatus(status, text) {
            statusIndicator.className = 'status-indicator ' + status;
            statusText.textContent = text;
        }

        // Add message to transcript
        function addMessage(text, type, isFinal = true) {
            if (type === 'user') {
                if (isFinal && text) {
                    const msg = document.createElement('div');
                    msg.className = 'message user';
                    msg.innerHTML = `<div class="message-label">Vy:</div>${text}`;
                    transcriptContent.appendChild(msg);
                    transcriptContent.scrollTop = transcriptContent.scrollHeight;
                    currentUserText = '';
                } else {
                    currentUserText = text;
                }
            } else if (type === 'assistant') {
                if (isFinal) {
                    if (currentAssistantText) {
                        const msg = document.createElement('div');
                        msg.className = 'message assistant';
                        msg.innerHTML = `<div class="message-label">Asistent:</div>${currentAssistantText}`;
                        transcriptContent.appendChild(msg);
                        transcriptContent.scrollTop = transcriptContent.scrollHeight;
                    }
                    currentAssistantText = '';
                } else {
                    currentAssistantText += text;
                }
            }
        }

        // Clear transcript
        function clearTranscript() {
            transcriptContent.innerHTML = '';
            currentUserText = '';
            currentAssistantText = '';
        }

        // Audio playback using Web Audio API (for ElevenLabs Flash v2.5 MP3 output)
        async function initAudioPlayback() {
            if (!audioContext) {
                // Use default sample rate (browser will handle MP3 decoding)
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                log(`AudioContext created: state=${audioContext.state}, sampleRate=${audioContext.sampleRate}Hz`, 'success');
            }
            
            // CRITICAL: Resume AudioContext if suspended (requires user interaction)
            if (audioContext.state === 'suspended') {
                log('AudioContext suspended, attempting to resume...', 'info');
                try {
                    await audioContext.resume();
                    log(`‚úÖ AudioContext resumed: state=${audioContext.state}`, 'success');
                } catch (error) {
                    log(`‚ùå Failed to resume AudioContext: ${error.message}`, 'error');
                }
            }
            
            // Double-check state
            if (audioContext.state !== 'running') {
                log(`‚ö†Ô∏è WARNING: AudioContext not running (state=${audioContext.state}). Audio may not play!`, 'error');
            }
        }

        // Play audio chunk (MP3 data from ElevenLabs)
        async function playAudioChunk(audioData) {
            if (!audioContext) {
                await initAudioPlayback();
            }

            try {
                const arrayBuffer = audioData instanceof ArrayBuffer ? audioData : audioData.buffer;
                log(`üîä Decoding audio chunk: ${arrayBuffer.byteLength} bytes`);
                
                const audioBuffer = await audioContext.decodeAudioData(arrayBuffer.slice(0));
                log(`‚úÖ Audio decoded: duration=${audioBuffer.duration.toFixed(2)}s, channels=${audioBuffer.numberOfChannels}`, 'success');
                
                const source = audioContext.createBufferSource();
                source.buffer = audioBuffer;
                source.connect(audioContext.destination);
                source.start(0);
                
                setStatus('speaking', 'Asistent mluv√≠...');
                
                source.onended = () => {
                    log('Audio chunk playback finished');
                    playNextInQueue();
                };
                
            } catch (error) {
                log(`‚ùå Error playing audio: ${error.message}`, 'error');
                log(`   AudioContext state: ${audioContext?.state}`, 'error');
                playNextInQueue();
            }
        }

        // Queue audio for sequential playback
        function queueAudio(audioData) {
            audioQueue.push(audioData);
            log(`üì• Audio chunk queued: ${audioData.byteLength} bytes (queue size: ${audioQueue.length})`);
            if (!isPlayingAudio) {
                playNextInQueue();
            }
        }

        // Play next audio in queue
        function playNextInQueue() {
            if (audioQueue.length > 0) {
                isPlayingAudio = true;
                assistantIsSpeaking = true;  // Pause microphone while speaking
                const audioData = audioQueue.shift();
                playAudioChunk(audioData);
            } else {
                isPlayingAudio = false;
                assistantIsSpeaking = false;  // Resume microphone
                if (isActive) {
                    setStatus('listening', 'Poslouch√°m...');
                }
            }
        }

        // Clear audio queue (for barge-in)
        function clearAudioQueue() {
            audioQueue = [];
            isPlayingAudio = false;
            assistantIsSpeaking = false;  // Resume microphone after barge-in
            // Stop any currently playing audio would require more complex handling
            log('Audio buffer cleared (barge-in)', 'success');
        }

        // Initialize microphone
        async function initMicrophone() {
            try {
                mediaStream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        sampleRate: SAMPLE_RATE,
                        channelCount: CHANNELS,
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true
                    }
                });
                
                log('Microphone access granted', 'success');
                return true;
                
            } catch (error) {
                log(`Microphone error: ${error.message}`, 'error');
                return false;
            }
        }

        // Process audio from microphone
        async function startAudioProcessing() {
            if (!mediaStream) return;

            const audioCtx = new (window.AudioContext || window.webkitAudioContext)({
                sampleRate: SAMPLE_RATE
            });

            const source = audioCtx.createMediaStreamSource(mediaStream);
            const analyser = audioCtx.createAnalyser();
            analyser.fftSize = 256;
            source.connect(analyser);

            // Use ScriptProcessor for audio capture (wider browser support)
            const processor = audioCtx.createScriptProcessor(4096, 1, 1);
            source.connect(processor);
            processor.connect(audioCtx.destination);

            const dataArray = new Uint8Array(analyser.frequencyBinCount);

            let audioChunkCount = 0;
            processor.onaudioprocess = (e) => {
                if (!isActive || !websocket || websocket.readyState !== WebSocket.OPEN) {
                    if (audioChunkCount > 0 && audioChunkCount % 100 === 0) {
                        log(`Audio not sent: active=${isActive}, ws=${websocket?.readyState}`, 'error');
                    }
                    return;
                }

                // Don't send audio while assistant is speaking (prevents echo/feedback)
                if (assistantIsSpeaking) {
                    return;
                }

                // Get audio data
                const inputData = e.inputBuffer.getChannelData(0);
                
                // Convert Float32 to Int16 PCM
                const pcmData = new Int16Array(inputData.length);
                for (let i = 0; i < inputData.length; i++) {
                    const s = Math.max(-1, Math.min(1, inputData[i]));
                    pcmData[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
                }

                // Send to WebSocket
                try {
                    websocket.send(pcmData.buffer);
                    audioChunkCount++;
                    // Log every 100 chunks (roughly every 25 seconds)
                    if (audioChunkCount % 100 === 0) {
                        log(`Sending audio... (${audioChunkCount} chunks sent)`);
                    }
                } catch (err) {
                    log(`Error sending audio: ${err.message}`, 'error');
                }

                // Update visualizer
                analyser.getByteFrequencyData(dataArray);
                const levels = Array.from(dataArray.slice(0, 32)).map(v => v / 255);
                updateVisualizer(levels);
            };

            audioWorklet = { processor, audioCtx, analyser };
            log('Audio processing started', 'success');
        }

        // Stop audio processing
        function stopAudioProcessing() {
            if (audioWorklet) {
                audioWorklet.processor.disconnect();
                audioWorklet.audioCtx.close();
                audioWorklet = null;
            }
            
            if (mediaStream) {
                mediaStream.getTracks().forEach(track => track.stop());
                mediaStream = null;
            }
            
            resetVisualizer();
            log('Audio processing stopped');
        }

        // Connect WebSocket
        function connectWebSocket() {
            return new Promise((resolve, reject) => {
                log(`Connecting to ${WS_URL}...`);
                
                websocket = new WebSocket(WS_URL);
                
                websocket.onopen = () => {
                    log('WebSocket connected', 'success');
                    setStatus('connected', 'P≈ôipojeno');
                    resolve();
                };
                
                websocket.onclose = (event) => {
                    log(`WebSocket closed: code=${event.code}, reason="${event.reason}", clean=${event.wasClean}`, event.wasClean ? 'info' : 'error');
                    setStatus('', 'Odpojeno');
                    if (isActive) {
                        stop();
                    }
                };
                
                websocket.onerror = (error) => {
                    log('WebSocket error', 'error');
                    reject(error);
                };
                
                websocket.onmessage = async (event) => {
                    if (event.data instanceof Blob) {
                        // Binary audio data
                        const arrayBuffer = await event.data.arrayBuffer();
                        queueAudio(arrayBuffer);
                    } else {
                        // JSON message
                        try {
                            const message = JSON.parse(event.data);
                            handleMessage(message);
                        } catch (e) {
                            log(`Invalid JSON: ${event.data}`, 'error');
                        }
                    }
                };
            });
        }

        // Handle incoming messages
        function handleMessage(message) {
            switch (message.type) {
                case 'session_started':
                    log('Session started', 'success');
                    setStatus('listening', 'Poslouch√°m...');
                    break;
                    
                case 'user_text':
                    addMessage(message.text, 'user', message.is_final);
                    if (!message.is_final) {
                        log(`User (interim): ${message.text}`);
                    } else {
                        log(`User: ${message.text}`, 'success');
                    }
                    break;
                    
                case 'assistant_text':
                    addMessage(message.text, 'assistant', message.is_final);
                    if (!message.is_final && message.text) {
                        // Don't log every token, too noisy
                    } else if (message.is_final) {
                        log('Assistant response complete', 'success');
                    }
                    break;
                    
                case 'clear_audio':
                    log('Barge-in: Clearing audio', 'success');
                    clearAudioQueue();
                    setStatus('listening', 'Poslouch√°m...');
                    break;
                    
                case 'audio_end':
                    log('Audio stream ended');
                    break;
                    
                case 'listening':
                    log('Ready for input', 'success');
                    setStatus('listening', 'Poslouch√°m...');
                    break;
                
                case 'session_timeout':
                    log('Session timed out due to inactivity', 'error');
                    setStatus('', 'ƒåasov√Ω limit - odpojeno');
                    stop();
                    // Add timeout message to transcript
                    const timeoutMsg = document.createElement('div');
                    timeoutMsg.className = 'message';
                    timeoutMsg.style.color = 'rgba(255,150,150,0.8)';
                    timeoutMsg.style.fontStyle = 'italic';
                    timeoutMsg.innerHTML = '<div class="message-label">Syst√©m:</div>Relace byla ukonƒçena kv≈Øli neaktivitƒõ.';
                    transcriptContent.appendChild(timeoutMsg);
                    break;
                    
                case 'error':
                    log(`Server error: ${message.message}`, 'error');
                    break;
                    
                case 'pong':
                    // Heartbeat response
                    break;
                    
                default:
                    log(`Unknown message type: ${message.type}`);
            }
        }

        // Start session
        async function start() {
            try {
                startButton.disabled = true;
                
                // Initialize audio playback context (needs user interaction)
                await initAudioPlayback();
                
                // Get microphone access
                if (!await initMicrophone()) {
                    throw new Error('Failed to access microphone');
                }
                
                // Connect WebSocket
                await connectWebSocket();
                
                // Start processing audio
                await startAudioProcessing();
                
                isActive = true;
                startButton.textContent = 'Zastavit';
                startButton.classList.add('active');
                startButton.disabled = false;
                
                // Clear old transcript
                clearTranscript();
                
                log('Voice session active', 'success');
                
            } catch (error) {
                log(`Start error: ${error.message}`, 'error');
                stop();
                startButton.disabled = false;
            }
        }

        // Stop session
        function stop() {
            isActive = false;
            
            // Send stop message
            if (websocket && websocket.readyState === WebSocket.OPEN) {
                websocket.send(JSON.stringify({ type: 'stop' }));
                websocket.close();
            }
            websocket = null;
            
            // Stop audio processing
            stopAudioProcessing();
            
            // Clear audio queue
            clearAudioQueue();
            
            // Reset UI
            startButton.textContent = 'Spustit';
            startButton.classList.remove('active');
            setStatus('', 'Odpojeno');
            
            log('Session stopped');
        }

        // Toggle session
        function toggle() {
            if (isActive) {
                stop();
            } else {
                start();
            }
        }

        // Heartbeat to keep connection alive
        setInterval(() => {
            if (websocket && websocket.readyState === WebSocket.OPEN) {
                websocket.send(JSON.stringify({ type: 'ping' }));
            }
        }, 30000);

        // Initialize
        document.addEventListener('DOMContentLoaded', () => {
            initVisualizer();
            startButton.addEventListener('click', toggle);
            
            // Log environment info
            log(`Protocol: ${window.location.protocol}`);
            log(`Host: ${window.location.host}`);
            log(`Secure context: ${window.isSecureContext}`);
            
            // Check for required APIs
            if (!window.isSecureContext) {
                log('ERROR: Str√°nka nie je v secure context!', 'error');
                log('Mikrof√≥n vy≈æaduje HTTPS. Pou≈æi https:// URL', 'error');
                startButton.disabled = true;
            } else if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                log('getUserMedia nie je dostupn√©', 'error');
                log('Sk√∫s obnovi≈• str√°nku alebo povoli≈• mikrof√≥n v nastaveniach', 'error');
                startButton.disabled = true;
            }
            
            if (!window.WebSocket) {
                log('WebSocket nie je podporovan√Ω', 'error');
                startButton.disabled = true;
            }
            
            if (!startButton.disabled) {
                log('Klient pripraven√Ω - klikni Spustit', 'success');
            }
        });
    </script>
</body>
</html>
